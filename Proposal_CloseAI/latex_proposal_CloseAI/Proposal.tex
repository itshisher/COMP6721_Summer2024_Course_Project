% CVPR 2022 Paper Template
% based on the CVPR template provided by Ming-Ming Cheng (https://github.com/MCG-NKU/CVPR_Template)
% modified and extended by Stefan Roth (stefan.roth@NOSPAMtu-darmstadt.de)

\documentclass[10pt,twocolumn,letterpaper]{article}

%%%%%%%%% PAPER TYPE  - PLEASE UPDATE FOR FINAL VERSION
% \usepackage[review]{cvpr}      % To produce the REVIEW version
%\usepackage{cvpr}              % To produce the CAMERA-READY version
%\usepackage[pagenumbers]{cvpr} % To force page numbers, e.g. for an arXiv version

% Include other packages here, before hyperref.
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{enumitem}
\usepackage{hyperref}
\usepackage[textheight=10in]{geometry}

% It is strongly recommended to use hyperref, especially for the review version.
% hyperref with option pagebackref eases the reviewers' job.
% Please disable hyperref *only* if you encounter grave issues, e.g. with the
% file validation for the camera-ready version.
%
% If you comment hyperref and then uncomment it, you should delete
% ReviewTempalte.aux before re-running LaTeX.
% (Or just hit 'q' on the first LaTeX run, let it finish, and you
%  should be clear).
\usepackage[breaklinks,colorlinks]{hyperref}


% Support for easy cross-referencing
\usepackage[capitalize]{cleveref}
\crefname{section}{Sec.}{Secs.}
\Crefname{section}{Section}{Sections}
\Crefname{table}{Table}{Tables}
\crefname{table}{Tab.}{Tabs.}


%%%%%%%%% PAPER ID  - PLEASE UPDATE
% \def\cvprPaperID{*****} % *** Enter the CVPR Paper ID here
% \def\confName{CVPR}
% \def\confYear{2022}


\begin{document}
\date{}
%%%%%%%%% TITLE - PLEASE UPDATE
\title{Project proposal for Places Database}

\author{Group CloseAI\\
Yang Cao 26654029\\
Hongwu Li 40280054\\
Bo Shi 40292839
}
\maketitle

%%%%%%%%% ABSTRACT

%%%%%%%%% BODY TEXT
% \section{Introduction}
% \label{sec:intro}

% \hspace{0.5cm} In this proposal, we will generally discuss the topics in our location classification project covering dataset, possible methodology and expectations. Aiming to point out our selection of dataset and possible solution addressing this task.

%-------------------------------------------------------------------------

%------------------------------------------------------------------------
\section{Dataset}
\hspace{0.5cm} In terms of dataset, we use a subset of the MIT Places365 dataset\cite{zhou2017places} which contains 5150 pictures of 5 classes out of 365 classes from the original dataset.(For the original MIT Places365 dataset, see: \href{http://places2.csail.mit.edu/download-private.html} {The Original Dataset}) This dataset consists of 365 classes of different scene-centric pictures that all contains representative features of various locations. All the images are JPEG color images and resized to 256*256 resolution.

\hspace{0.1cm} With consideration of robustness and fitness, the five classes chosen from the original dataset are general, representative locations with specific features. The five classes are:
\setlist{nolistsep}
\begin{itemize}[noitemsep]
    \item homeOffice (1346/5150)
    \item hotelRoom (1524/5150)
    \item church (797/5150)
    \item museum (760/5150)
    \item supermarket (1466/5150)
\end{itemize}
\hspace{0.5cm} 

For better performance from the classifier, every sampled image is taken from real life, including people or all possible surroundings, so that the model could possibly be more robust. In our dataset, the quantities of all five classes are balanced, with each class containing 700 images, and are divided into training and testing images in an 8:2 ratio. Our dataset is finally presented as followsï¼š

\setlist{nolistsep}
\begin{itemize}[noitemsep]
    \item homeOffice (700/3500)
    \item hotelRoom (700/3500)
    \item church (700/3500)
    \item museum (700/3500)
    \item supermarket (700/3500)
\end{itemize}


\section{Methodology}
% \hspace{0.5cm}We will use supervised decision tree, semi-supervised decision tree, and supervised CNN as our methods to solve the problem. Common steps for all methods are data loading and data preprocessing.
\indent\textbf{Data loading:}
\setlist{nolistsep}
\begin{itemize}[noitemsep]
    \item Load the image dataset and associated labels.
    \item Split the dataset into training, testing, and validation image sets.
\end{itemize}

% \textbf{Data preprocessing:}
% \setlist{nolistsep}
% \begin{itemize}[noitemsep]
%     \item Resize images to a consistent size.
%     \item Normalization of images and encoding labels into numerical format.
% \end{itemize}

% \subsection{Supervised Decision Tree}
% \hspace{0.5cm} This method is used for both classification and regression tasks\cite{Supervised_DT}, representing decisions and their possible outcomes in a tree structure. It operates by initially extracting features from images, such as color histograms, textures, or embeddings from pre-trained CNNs. The algorithm is then trained using these features and their corresponding labels to formulate decision rules. When making predictions, new images are classified by navigating through the tree based on their features.

% \subsection{Semi-supervised Decision Tree}
% \hspace{0.5cm} Semi-supervised learning utilizes both labeled and unlabeled data for training, enhancing the performance of models like Decision Trees since we will need to train multiple Decision Trees iteratively taking into account the labeled data and more confident predicted labels. Initially, the Decision Tree is trained on a labeled subset of images. Then, it predicts labels for the unlabeled images which known as pseudo-labeling. The labeled and pseudo-labeled data are combined, and the model is retrained. Finally, the retrained model is used to classify images\cite{semiDT}.

% \subsection{Supervised CNN}
% \hspace{0.5cm} Convolutional Neural Networks (CNNs) are deep learning models tailored for grid-like data like images, learning spatial hierarchies through convolutional layers\cite{image_net}. Initially, data undergoes augmentation for diversity. Then, a custom or pre-trained CNN architecture is chosen. The model trains on raw pixel values, extracting features via convolutional, pooling, and fully connected layers. Lastly, images are classified through the trained CNN\cite{gradient_based}. This method will be implemented using PyTorch library. 



\subsection{Metrics}
\hspace{0.5cm} Metrics are quantitative measures used to assess the performance of the models. We will ensure that all methods will be evaluated using the same metrics listed following.
\setlist{nolistsep}
\begin{enumerate}[noitemsep]
    \item Accuracy
    \item Precision
    \item Recall
    \item F1-Score
    \item Confusion matrix
\end{enumerate}


\subsection{Comparison and Analysis}
\hspace{0.5cm} By comparing these methods using following strategies, we can determine which approach best solves the problem of classifying images into venue labels considering both performance and practical constraints.\\
\indent\textbf{Standardized Metrics:} Compare accuracy, precision, recall, F1-Score for all three methods.\\
\indent\textbf{Performance Visualization:} Compare confusion matrix for all three methods to visualize wrong classifications.\\
\indent\textbf{Computational Complexity:} Consider training time and computational resources required for each method.\\
\indent\textbf{Optimization:} Focus on models' performance through hyperparameter tuning. For Decision Trees, parameters like depth, number of branches, and pruning options need to be adjusted, while for the CNN, modifications such as adding or removing pooling layers and altering the number of convolutional layers are explored.


\subsection{Expectations}
\hspace{0.5cm} The supervised Decision Tree performs well on straightforward datasets, but may overfit, while semi-supervised Decision Tree outperforms it with significant unlabeled data, depending on accurate pseudo-labeling. The CNN method is expected to provide the best performance on complex datasets like images but requires more computational resources and sacrifices interpretability. However, this is based on past experience and overall performance of these models. A final conclusion will be made by comparing these methods systematically. After that, we can determine the best approach considering both performance and practical limitations.

\newpage

\label{sec:formatting}



%-------------------------------------------------------------------------
\bibliographystyle{IEEEtran}
\bibliography{latex/proposal}
\end{document}

